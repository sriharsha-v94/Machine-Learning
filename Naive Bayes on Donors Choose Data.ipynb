{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnubs-Nnb3cw"
      },
      "source": [
        "# Assignment 6: Apply NB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW0zYHb5m_wI"
      },
      "source": [
        "<ol>\n",
        "    <li>Minimum data points need to be considered for people having 4GB RAM is <strong>50k</strong> and for 8GB RAM is <strong>100k</strong></li>\n",
        "    <li>When you are using ramdomsearchcv or gridsearchcv you need not split the data into X_train,X_cv,X_test. As the above methods use kfold. The model will learn better if train data is more so splitting to X_train,X_test will suffice.</li>\n",
        "    <li>If you are writing for loops to tune your model then you need split the data into X_train,X_cv,X_test.</li>\n",
        "    <li>While splitting the data explore stratify parameter. </li>\n",
        "    <li><strong>Apply Multinomial NB on these feature sets</strong></li>\n",
        "        <ul>\n",
        "            <li>Features that need to be considered</li> \n",
        "                <dl>\n",
        "                  <dt>essay</dt>\n",
        "                    <dd>while encoding essay, try to experiment with the max_features and n_grams parameter of vectorizers and see if it increases AUC score.</dd>\n",
        "                  <dt>categorical features</dt>\n",
        "                  <dd> - teacher_prefix</dd>\n",
        "                  <dd> - project_grade_category</dd>\n",
        "                  <dd> - school_state</dd>\n",
        "                  <dd> - clean_categories</dd>\n",
        "                  <dd> - clean_subcategories</dd>\n",
        "                  <dt>numerical features</dt>\n",
        "                  <dd> - price</dd>\n",
        "                  <dd> - teacher_number_of_previously_posted_projects</dd>\n",
        "                  <dd>while encoding the numerical features check <a href='https://imgur.com/ldZA1zg'>this</a> and <a href='https://ac-classroom-production.s3.amazonaws.com/public/COMMENT/Annotation_2020-05-21_225912_0lyZzN8.jpg'>this</a></dd>\n",
        "                </dl>    \n",
        "            <li><font color='red'>Set 1</font>: categorical, numerical features + preprocessed_eassay (BOW)</li>\n",
        "            <li><font color='red'>Set 2</font>: categorical, numerical features + preprocessed_eassay (TFIDF)</li>\n",
        "        </ul>\n",
        "    <li><strong>The hyper paramter tuning(find best alpha:smoothing parameter)</strong>\n",
        "        <ul>\n",
        "    <li>Consider alpha values in range: 10^-5 to 10^2 like [0.00001,0.0005, 0.0001,0.005,0.001,0.05,0.01,0.1,0.5,1,5,10,50,100]</li>\n",
        "    <li>Explore class_prior = [0.5, 0.5] parameter which can be present in MultinomialNB function(go through <a href='https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html'>this</a> ) then check how results might change.\n",
        "    <li>Find the best hyper parameter which will give the maximum <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/receiver-operating-characteristic-curve-roc-curve-and-auc-1/'>AUC</a> value</li>\n",
        "    <li>For hyper parameter tuning using k-fold cross validation(use GridsearchCV or RandomsearchCV)/simple cross validation data (write for loop to iterate over hyper parameter values)</li>\n",
        "    <li>You need to plot the performance of model both on train data and cross validation data for each hyper parameter, like shown in the figure\n",
        "    <img src='https://i.imgur.com/hUv6aEy.jpg' width=300px><dd>-while plotting take log(alpha) on your X-axis so that it will be more readable</dd></li>\n",
        "    <li>Once after you found the best hyper parameter, you need to train your model with it, and find the AUC on test data and plot the ROC curve on both train and test.\n",
        "    <img src='https://imgur.com/q2P65L5.jpg' width=300px></li>\n",
        "    <li>Along with plotting ROC curve, you need to print the <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/confusion-matrix-tpr-fpr-fnr-tnr-1/'>confusion matrix</a> with predicted and original labels of test data points\n",
        "        <img src='https://i.imgur.com/IdN5Ctv.png' width=300px><dd>-plot the confusion matrix in heatmaps, while plotting the confusion matrix go through the <a href='https://stackoverflow.com/questions/61748441/how-to-fix-the-values-displayed-in-a-confusion-matrix-in-exponential-form-to-nor'>link </a>\n",
        "</dd></li>\n",
        "        </ul>\n",
        "<li>find the top 20 features from either from feature <font color='red'>Set 1</font> or feature <font color='red'>Set 2</font> using values of `feature_log_prob_ ` parameter of `MultinomialNB` \n",
        "(https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) and print <strong>BOTH</strong> positive as well as negative corresponding feature names. <dd> - go through the <a href='https://imgur.com/mWvE7gj'>link </a> </dd>\n",
        "    </li>\n",
        "    <li>You need to summarize the results at the end of the notebook, summarize it in the table format\n",
        "        <img src='http://i.imgur.com/YVpIGGE.jpg' width=400px>\n",
        "    </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chpSjDaXm9KG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inzYCIaib3c3"
      },
      "source": [
        "<h1>2. Naive Bayes </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYqCIxzFb3c5"
      },
      "source": [
        "## 1.1 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA1jknyqb3c_"
      },
      "outputs": [],
      "source": [
        "#make sure you are loading atleast 50k datapoints\n",
        "#you can work with features of preprocessed_data.csv for the assignment.\n",
        "# If you want to add more features, you can add. (This is purely optional, not mandatory)\n",
        "\n",
        "import pandas\n",
        "data = pandas.read_csv('preprocessed_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtVV13Fyb3dH"
      },
      "source": [
        "<h2>1.2 Splitting data into Train and cross validation(or test): Stratified Sampling</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P98jHnoInY1V"
      },
      "outputs": [],
      "source": [
        "# write your code in following steps for task 1\n",
        "# 1. Split your data.\n",
        "# 2. Perform Bag of Words Vectorization of text data.\n",
        "# 3. Perform tfidf vectorization of text data.\n",
        "# 4. perform one-hot encoding of categorical features.\n",
        "# 5. perform normalization of numerical features\n",
        "# 6. For set 1 stack up all the features using hstack()\n",
        "# 7. For set 2 stack up all the features using hstack()\n",
        "# 8. Perform hyperparameter tuning and represent the training and cross-validation AUC scores for different 'alpha' values, using a 2D line plot.\n",
        "# 9. Find the best hyperparameter 'alpha' and fit the model. Plot ROC-AUC curve(by obtaining the probabilities using 'predict proba' method)\n",
        "# 10. Plot confusion matrix based on the best threshold value\n",
        "# 11. Either for the model in set 1 or in set 2, print the top 20 features(you have to print the names, not the indexes) associated with the positive and negative classes each.\n",
        "# 12. Summarize your observations and compare both the models(ie., from set 1 and set 2) in terms of optimal hyperparameter value, train AUC and test AUC scores. \n",
        "# 13. You can use Prettytable or any other tabular format for comparison.\n",
        "\n",
        "\n",
        "# please write all the code with proper documentation, and proper titles for each subsection\n",
        "# go through documentations and blogs before you start coding\n",
        "# first figure out what to do, and then think about how to do.\n",
        "# reading and understanding error messages will be very much helpfull in debugging your code\n",
        "# when you plot any graph make sure you use \n",
        "    # a. Title, that describes your plot, this will be very helpful to the reader\n",
        "    # b. Legends if needed\n",
        "    # c. X-axis label\n",
        "    # d. Y-axis label\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-PyprDNb3dI"
      },
      "outputs": [],
      "source": [
        "# Split the dataset \n",
        "# 1) If you want to apply simple cross-validation, split the dataset into 3 parts (ie., train, CV and test sets)\n",
        "# 2) If you want to apply K-fold CV (or) GridSearch Cross Validation (or) Randomized Search Cross Validation, just split the dataset into 2 parts (ie., train and test sets)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnZwVNULb3dO"
      },
      "source": [
        "<h2>1.3 Make Data Model Ready: encoding essay, and project_title</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49FGuSisnY1W"
      },
      "outputs": [],
      "source": [
        "# Apply Bag of Words (BOW) vectorization on 'Preprocessed_Essay' \n",
        "# Apply Bag of Words (BOW) vectorization on 'Preprocessed_Title' (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-R3djoinY1X"
      },
      "outputs": [],
      "source": [
        "# Apply TF-IDF vectorization on 'Preprocessed_Essay' \n",
        "# Apply TF-IDF vectorization on 'Preprocessed_Title' (Optional)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGy86kgHb3dX"
      },
      "source": [
        "<h2>1.4 Make Data Model Ready: encoding numerical, categorical features</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfXkofX1b3da"
      },
      "outputs": [],
      "source": [
        "# Apply One-Hot Encoding on the categorical features either using OneHotEncoder() (or) CountVectorizer(binary=True)\n",
        "# Apply Normalization on the numerical features using Normalizer().\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYHPYadYb3dh"
      },
      "source": [
        "<h2>1.5 Appling NB on different kind of featurization as mentioned in the instructions</h2>\n",
        "\n",
        "<br>Apply NB on different kind of featurization as mentioned in the instructions\n",
        "<br> For Every model that you work on make sure you do the step 2 and step 3 of instrucations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNwqilFxb3di"
      },
      "source": [
        "#### Set 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKu-Ecw_nY1Y"
      },
      "outputs": [],
      "source": [
        "# Perform Hyperparameter Tuning.\n",
        "# Plot the training and the CV AUC scores, for different values of 'alpha', using a 2D line plot\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkJM9NCDnY1Y"
      },
      "outputs": [],
      "source": [
        "# Obtain the optimal value for 'alpha' and using the obtained optimal 'alpha' value, fit a multinomial naive bayes model, on the train data,\n",
        "# Note: If you have split the datase into 3 parts (ie., train, cv and test sets) in the beginning, then the training datafor this final model would be (train set + cv set)\n",
        "# Make class label and probability predictions on the train and test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxkip5kvnY1Y"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC-AUC curves using the probability predictions made on train and test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThxkZ9ENnY1Y"
      },
      "outputs": [],
      "source": [
        "# Pick the best threshold among the probability estimates, such that it has to yield maximum value for TPR*(1-FPR)\n",
        "# Plot the confusion matrices(each for train and test data) afer encoding the predicted class labels, on the basis of the best threshod probability estimate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB3UeFH0nY1Z"
      },
      "source": [
        "#### Set 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlWL17sunY1Z"
      },
      "outputs": [],
      "source": [
        "# Perform Hyperparameter Tuning.\n",
        "# Plot the training and the CV AUC scores, for different values of 'alpha', using a 2D line plot\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWF-dySxnY1Z"
      },
      "outputs": [],
      "source": [
        "# Obtain the optimal value for 'alpha' and using the obtained optimal 'alpha' value, fit a multinomial naive bayes model, on the train data,\n",
        "# Note: If you have split the datase into 3 parts (ie., train, cv and test sets) in the beginning, then the training datafor this final model would be (train set + cv set)\n",
        "# Make class label and probability predictions on the train and test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWh-OsCYnY1Z"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC-AUC curves using the probability predictions made on train and test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2MG6AYfnY1Z"
      },
      "outputs": [],
      "source": [
        "# Pick the best threshold among the probability estimates, such that it has to yield maximum value for TPR*(1-FPR)\n",
        "# Plot the confusion matrices(each for train and test data) afer encoding the predicted class labels, on the basis of the best threshod probability estimate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VFMp3YZnY1Z"
      },
      "outputs": [],
      "source": [
        "# Either from set 1 (or) set 2, print the names of the top 20 features associated with the positive and negative classes each. (You have to print the names of the features, but not the indexes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9hIHdib3dp"
      },
      "source": [
        "<h1>3. Summary</h1>\n",
        "\n",
        "<br> as mentioned in the step 5 of instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W58z3T0dnY1a"
      },
      "outputs": [],
      "source": [
        "#Summarize your assignment work here in a few points, and also compare the final models (from set 1 and set 2), in terms of optimal hyperparameter value 'alpha', training AUC and test AUC scores.\n",
        "# You can either use a pretty table or any other tabular structure.\n",
        "# Reference Link for Pretty table:  https://pypi.org/project/prettytable/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NB_Assignment_instructions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}